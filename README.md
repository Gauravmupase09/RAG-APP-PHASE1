# ğŸ“˜ RAG-APP-PHASE1 â€” Chat With Your Documents

RAG-APP is a complete Retrieval-Augmented Generation system where users can upload documents (PDF, DOCX, TXT), process them, and instantly chat with their content using LLMs â€” along with accurate, clickable citations.

---

**It includes:**

âš¡ FastAPI backend

ğŸ¨ Streamlit frontend

ğŸ§  BGE-small embedding model

ğŸ—ƒï¸ Qdrant vector database

ğŸ§µ Session-aware memory

ğŸ”— Precise source citations

---

## ğŸš€ Project Overview

| Feature |	Description	| Why it Matters |
|------|--------------|-------------|
| **Document Upload**	| Accepts PDF, DOCX, TXT | Flexible input formats |
| **Processing Pipeline** | Extract â†’ Clean â†’ Chunk â†’ Embed â†’ Store	| Full RAG preparation |
| **Qdrant Vector DB** | Stores embeddings for semantic search | Fast & scalable RAG |
| **LLM Querying**	| Chat with documents	| Real-time question answering |
| **Session Memory**	| Maintains conversation context	| More coherent answers |
| **Citations Engine**	| Clickable sources with chunk details	| Transparency & trust |

---

## ğŸ—ï¸ System Architecture

```bash
User â†’ Streamlit UI â†’ FastAPI Backend â†’ Qdrant Vector DB
                             â†“
                       LLM (Gemini)
                             â†“
                     Response + Citations
```

## ğŸ“ Project Structure

```bash
APP/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py
â”‚   â”‚   â”‚   â”œâ”€â”€ process.py
â”‚   â”‚   â”‚   â”œâ”€â”€ query.py
â”‚   â”‚   â”‚   â”œâ”€â”€ reset_session.py
â”‚   â”‚   â”‚   â””â”€â”€ list_docs.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ text_extractor.py
â”‚   â”‚   â”œâ”€â”€ text_cleaner.py
â”‚   â”‚   â”œâ”€â”€ chunking.py
â”‚   â”‚   â”œâ”€â”€ embedding_engine.py
â”‚   â”‚   â”œâ”€â”€ model_manager.py
â”‚   â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â”‚   â”‚   â”œâ”€â”€ citation_handler.py
â”‚   â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_engine.py
â”‚   â”‚   â”‚   â””â”€â”€ session_memory.py
â”‚   â”‚   â””â”€â”€ qdrant_manager.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ file_manager.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ uploads/
â”‚   â”‚   â””â”€â”€ processed/
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”‚
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ upload_section.py
â”‚   â”‚   â”œâ”€â”€ chat_section.py
â”‚   â”‚   â””â”€â”€ citation_box.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ api_client.py
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”‚
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
---

## âš™ï¸ Tech Stack

| Layer	| Technology |
|------|--------------|
| **Frontend**	| Streamlit, Requests |
| **Backend** |	FastAPI, Uvicorn |
| **Embeddings** |	BAAI/bge-small-en-v1.5 |
| **Vector DB**	| Qdrant (Docker) |
| **LLM	Google** | Gemini API |
| **Processing**	| PyPDF, Docx, TextCleaner |

---

## ğŸ› ï¸ Installation & Setup

## 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/Gauravmupase09/RAG-APP.git
cd RAG-APP
```
---

## ğŸ”§ Backend Setup (FastAPI)

## 2ï¸âƒ£ Create Virtual Environment
```bash
cd backend
python -m venv venv
venv\Scripts\activate
```
---

## 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
---

## 4ï¸âƒ£ Start Qdrant (Docker)
```bash
docker pull qdrant/qdrant
docker run -p 6333:6333 qdrant/qdrant
```
Then run backend:
```bash
uvicorn main:app --reload
```
Backend available at:

ğŸ‘‰ http://localhost:8000

ğŸ‘‰ http://localhost:8000/docs

---

## ğŸ¨ Frontend Setup (Streamlit)
```bash
cd ../frontend
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
streamlit run app.py
```
Frontend available at:
ğŸ‘‰ http://localhost:8501

---

## ğŸ”„ Workflow: How the App Works

## ğŸ“¤ 1. Upload Documents

- Upload PDF, DOCX, or TXT

- Stored in session-specific folder

## âš™ï¸ 2. Process Documents

- Processing pipeline:

| Step | Action |
|------|--------------|
| 1	| Extract text |
| 2 |	Clean & normalize text |
| 3	| Chunk documents |
| 4	| Generate embeddings |
| 5 | Upsert to Qdrant |

## ğŸ’¬ 3. Chat With Your Documents

- Ask any question

- Top-k chunk retrieval

- LLM response with memory

- Citation panel shows:
  
  - File name

  - Chunk number

  - Semantic score

  - Clickable PDF source

---

## ğŸ“š API Reference

| Method |	Route |	Description |
|------|--------------|-------------|
| **POST** |	/api/upload	| Upload document |
| **POST** |	/api/process/{session_id}	| Run processing pipeline |
| **POST**	| /api/query/{session_id}	| Query documents |
| **GET**	| /api/list_docs	| List uploaded documents |
| **POST**	| /api/reset_session	| Clear session & Qdrant |

---

## ğŸ§  RAG Pipeline Internals

**ğŸ”¹ Retrieval Step**

- Vectorize query

- Search in Qdrant

- Get top-k chunks with scores

**ğŸ”¹ Augmentation**

- Merge:

  - context chunks
  
  - session memory

**ğŸ”¹ Generation**

- Gemini API produces final answer

- Citations formatted & returned

---

## ğŸ¯ Key Features
| Feature |	Benefit |
|------|--------------|
| Session-based storage	| Multi-document conversations |
| Chunk-level citations	| Accurate reference tracking |
| Memory-aware chat	| More natural responses |
| Streamlit UI	|Clean and simple |
| FastAPI backend	| High-performance processing |
| Docker Qdrant	| Zero-config vector DB |

---

## ğŸ“ Example Output

**â“ Query**

"Give me a summary of the project abstract."

**ğŸ’¡ Answer**

(Generated by LLM + retrieved chunks)

**ğŸ“š Citations**

- Project Abstract.pdf (chunk 1/2)

- Project Abstract.pdf (chunk 2/2)

---

## ğŸ¤ Contributing

Pull requests are welcome!
Feel free to open issues or suggest improvements.

---

## ğŸ“œ License

MIT License


